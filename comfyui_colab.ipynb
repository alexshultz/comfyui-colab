{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexshultz/comfyui-colab/blob/main/comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "# Install xFormers for CUDA 12.4 first\n",
        "!pip install xformers!=0.0.18 --index-url https://download.pytorch.org/whl/cu124\n",
        "# Then install remaining requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# InsightFace and onnxruntime\n",
        "!echo -= Installing InsightFace and onnxruntime for IP-Adapter FaceID =-\n",
        "!pip install insightface onnxruntime-gpu\n",
        "\n",
        "# Update or install IP-Adapter custom nodes\n",
        "!echo -= Updating ComfyUI_IPAdapter_plus =-\n",
        "# If directory exists and is a git repo, update it; otherwise, clone fresh\n",
        "!cd /content/drive/MyDrive/ComfyUI/custom_nodes && (cd ComfyUI_IPAdapter_plus && git pull || git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus.git ComfyUI_IPAdapter_plus)\n",
        "# Install dependencies\n",
        "!if [ -f /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus/requirements.txt ]; then pip install -r /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus/requirements.txt; else echo \"requirements.txt missing, installing manually\" && pip install insightface opencv-python-headless numpy torch torchvision; fi\n",
        "\n",
        "# Update or install ComfyUI_essentials custom nodes\n",
        "!echo -= Updating ComfyUI_essentials =-\n",
        "# If directory exists and is a git repo, update it; otherwise, clone fresh\n",
        "!cd /content/drive/MyDrive/ComfyUI/custom_nodes && (cd ComfyUI_essentials && git pull || git clone https://github.com/cubiq/ComfyUI_essentials.git ComfyUI_essentials)\n",
        "# Install dependencies\n",
        "!if [ -f /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_essentials/requirements.txt ]; then pip install -r /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_essentials/requirements.txt; else echo \"No additional requirements for ComfyUI_essentials\"; fi\n",
        "\n",
        "\n",
        "# Update or install Comfy_Dungeon custom nodes\n",
        "# https://github.com/cubiq/Comfy_Dungeon\n",
        "!echo -= Updating Comfy_Dungeon =-\n",
        "!cd /content/drive/MyDrive/ComfyUI/custom_nodes && (cd Comfy_Dungeon && git pull || git clone https://github.com/cubiq/Comfy_Dungeon.git Comfy_Dungeon)\n",
        "# No requirements.txt specified in README, assuming base ComfyUI deps suffice\n",
        "\n",
        "# Install huggingface model dowloader\n",
        "!echo -= huggingface_hub =-\n",
        "!pip install huggingface_hub\n",
        "\n",
        "\n",
        "!echo -= Done =-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)\n",
        "\n",
        "Great tools in the AP-Adapter package\n",
        "`https://github.com/cubiq/ComfyUI_IPAdapter_plus?tab=readme-ov-file`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from huggingface_hub import snapshot_download\n",
        "import hashlib\n",
        "\n",
        "# Get Hugging Face token from Colab Secrets\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')  # Add this to Secrets as 'HF_TOKEN'\n",
        "\n",
        "OPTIONS = {}\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "    !echo -= Updating ComfyUI =-\n",
        "    !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -r requirements.txt\n",
        "!pip install huggingface_hub insightface onnxruntime-gpu\n",
        "\n",
        "# Ensure standard ComfyUI directories exist\n",
        "base_dir = \"/content/drive/MyDrive/ComfyUI/models\"\n",
        "!mkdir -p {base_dir}/checkpoints\n",
        "!mkdir -p {base_dir}/loras\n",
        "!mkdir -p {base_dir}/ipadapter\n",
        "!mkdir -p {base_dir}/vae\n",
        "!mkdir -p {base_dir}/clip_vision\n",
        "!mkdir -p {base_dir}/controlnet\n",
        "!mkdir -p {base_dir}/style_models\n",
        "!mkdir -p {base_dir}/gligen\n",
        "!mkdir -p {base_dir}/upscale_models\n",
        "!mkdir -p {base_dir}/insightface\n",
        "!mkdir -p {base_dir}/hf_downloads\n",
        "\n",
        "# Download InsightFace buffalo_l models\n",
        "!echo -= Downloading InsightFace buffalo_l models =-\n",
        "!wget -c https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip -O {base_dir}/insightface/buffalo_l.zip\n",
        "!unzip -o {base_dir}/insightface/buffalo_l.zip -d {base_dir}/insightface/\n",
        "!rm {base_dir}/insightface/buffalo_l.zip\n",
        "\n",
        "# Update or install custom nodes\n",
        "!echo -= Updating ComfyUI_IPAdapter_plus =-\n",
        "!cd {base_dir}/../custom_nodes && (cd ComfyUI_IPAdapter_plus && git pull || git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus.git ComfyUI_IPAdapter_plus)\n",
        "!if [ -f {base_dir}/../custom_nodes/ComfyUI_IPAdapter_plus/requirements.txt ]; then pip install -r {base_dir}/../custom_nodes/ComfyUI_IPAdapter_plus/requirements.txt; else echo \"requirements.txt missing, installing manually\" && pip install insightface opencv-python-headless numpy torch torchvision onnxruntime-gpu; fi\n",
        "\n",
        "!echo -= Updating ComfyUI_essentials =-\n",
        "!cd {base_dir}/../custom_nodes && (cd ComfyUI_essentials && git pull || git clone https://github.com/cubiq/ComfyUI_essentials.git ComfyUI_essentials)\n",
        "!if [ -f {base_dir}/../custom_nodes/ComfyUI_essentials/requirements.txt ]; then pip install -r {base_dir}/../custom_nodes/ComfyUI_essentials/requirements.txt; else echo \"No additional requirements for ComfyUI_essentials\"; fi\n",
        "\n",
        "!echo -= Updating Comfy_Dungeon =-\n",
        "!cd {base_dir}/../custom_nodes && (cd Comfy_Dungeon && git pull || git clone https://github.com/cubiq/Comfy_Dungeon.git Comfy_Dungeon)\n",
        "\n",
        "!echo -= Updating comfy_controlnet_preprocessors =-\n",
        "!cd {base_dir}/../custom_nodes && (cd comfy_controlnet_preprocessors && git pull || git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors.git comfy_controlnet_preprocessors && python install.py)\n",
        "\n",
        "# Function to sort downloaded files into ComfyUI subdirectories\n",
        "def sort_hf_files(src_dir, base_dir):\n",
        "    def get_file_hash(file_path):\n",
        "        \"\"\"Calculate SHA256 hash of a file.\"\"\"\n",
        "        sha256 = hashlib.sha256()\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "                sha256.update(chunk)\n",
        "        return sha256.hexdigest()\n",
        "\n",
        "    for root, _, files in os.walk(src_dir):\n",
        "        for file in files:\n",
        "            src_path = os.path.join(root, file)\n",
        "            if file.endswith('.safetensors'):\n",
        "                if 'ip-adapter' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/ipadapter\"\n",
        "                elif 'lora' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/loras\"\n",
        "                elif 'vae' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/vae\"\n",
        "                elif 'clip-vit' in file.lower() or 'image_encoder' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/clip_vision\"\n",
        "                elif 'control' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/controlnet\"\n",
        "                elif 'style' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/style_models\"\n",
        "                elif 'gligen' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/gligen\"\n",
        "                else:\n",
        "                    dest_dir = f\"{base_dir}/checkpoints\"\n",
        "                dest_path = os.path.join(dest_dir, file)\n",
        "                # Copy if file doesn't exist or contents differ\n",
        "                if not os.path.exists(dest_path):\n",
        "                    shutil.copy2(src_path, dest_path)\n",
        "                    print(f\"Copied {file} to {dest_dir} (new file)\")\n",
        "                elif get_file_hash(src_path) != get_file_hash(dest_path):\n",
        "                    shutil.copy2(src_path, dest_path)\n",
        "                    print(f\"Copied {file} to {dest_dir} (updated content)\")\n",
        "                else:\n",
        "                    print(f\"Skipped {file} - already up-to-date in {dest_dir}\")\n",
        "            elif file.endswith(('.pth', '.ckpt', '.bin', '.pt')):\n",
        "                if 'vae' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/vae\"\n",
        "                elif 'control' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/controlnet\"\n",
        "                elif 'style' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/style_models\"\n",
        "                elif 'gligen' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/gligen\"\n",
        "                elif 'esrgan' in file.lower() or 'upscale' in file.lower():\n",
        "                    dest_dir = f\"{base_dir}/upscale_models\"\n",
        "                else:\n",
        "                    dest_dir = f\"{base_dir}/checkpoints\"\n",
        "                dest_path = os.path.join(dest_dir, file)\n",
        "                if not os.path.exists(dest_path):\n",
        "                    shutil.copy2(src_path, dest_path)\n",
        "                    print(f\"Copied {file} to {dest_dir} (new file)\")\n",
        "                elif get_file_hash(src_path) != get_file_hash(dest_path):\n",
        "                    shutil.copy2(src_path, dest_path)\n",
        "                    print(f\"Copied {file} to {dest_dir} (updated content)\")\n",
        "                else:\n",
        "                    print(f\"Skipped {file} - already up-to-date in {dest_dir}\")\n",
        "\n",
        "# Download models using snapshot_download\n",
        "!echo -= Downloading Models =-\n",
        "\n",
        "# Dreamshaper 8 (checkpoint via wget, as it's from Civitai)\n",
        "!wget -c https://civitai.com/api/download/models/128713 -O {base_dir}/checkpoints/dreamshaper_8.safetensors\n",
        "\n",
        "# ProteusV0.3\n",
        "print(\"Downloading ProteusV0.3...\")\n",
        "snapshot_download(repo_id=\"dataautogpt3/ProteusV0.3\", local_dir=f\"{base_dir}/hf_downloads/ProteusV0.3\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/ProteusV0.3\", base_dir)\n",
        "\n",
        "# dreamshaper-xl-v2-turbo\n",
        "print(\"Downloading dreamshaper-xl-v2-turbo...\")\n",
        "snapshot_download(repo_id=\"Lykon/dreamshaper-xl-v2-turbo\", local_dir=f\"{base_dir}/hf_downloads/dreamshaper-xl-v2-turbo\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/dreamshaper-xl-v2-turbo\", base_dir)\n",
        "\n",
        "# lcm-lora-sdxl\n",
        "print(\"Downloading lcm-lora-sdxl...\")\n",
        "snapshot_download(repo_id=\"latent-consistency/lcm-lora-sdxl\", local_dir=f\"{base_dir}/hf_downloads/lcm-lora-sdxl\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/lcm-lora-sdxl\", base_dir)\n",
        "\n",
        "# Stable Diffusion XL base 1.0\n",
        "print(\"Downloading SD-XL 1.0-base...\")\n",
        "snapshot_download(repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\", local_dir=f\"{base_dir}/hf_downloads/SD-XL_1.0-base\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/SD-XL_1.0-base\", base_dir)\n",
        "\n",
        "# clip_vision_g (SDXL ReVision)\n",
        "print(\"Downloading clip_vision_g...\")\n",
        "snapshot_download(repo_id=\"comfyanonymous/clip_vision_g\", local_dir=f\"{base_dir}/hf_downloads/clip_vision_g\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/clip_vision_g\", base_dir)\n",
        "\n",
        "# Stable Diffusion v1.5\n",
        "print(\"Downloading Stable Diffusion v1.5...\")\n",
        "snapshot_download(repo_id=\"Comfy-Org/stable-diffusion-v1-5-archive\", local_dir=f\"{base_dir}/hf_downloads/Stable_Diffusion_v1.5\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/Stable_Diffusion_v1.5\", base_dir)\n",
        "\n",
        "# OrangeMixs\n",
        "print(\"Downloading OrangeMixs...\")\n",
        "snapshot_download(repo_id=\"WarriorMama777/OrangeMixs\", local_dir=f\"{base_dir}/hf_downloads/OrangeMixs\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/OrangeMixs\", base_dir)\n",
        "\n",
        "# Anything V3 (gated, requires token)\n",
        "# Uncomment and add token if you have access\n",
        "# print(\"Downloading Anything V3...\")\n",
        "# snapshot_download(repo_id=\"Linaqruf/anything-v3.0\", local_dir=f\"{base_dir}/hf_downloads/Anything_V3\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"], token=\"YOUR_HF_TOKEN\")\n",
        "# sort_hf_files(f\"{base_dir}/hf_downloads/Anything_V3\", base_dir)\n",
        "\n",
        "# IP-Adapter\n",
        "print(\"Downloading IP-Adapter...\")\n",
        "snapshot_download(repo_id=\"h94/IP-Adapter\", local_dir=f\"{base_dir}/hf_downloads/IP-Adapter\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/IP-Adapter\", base_dir)\n",
        "\n",
        "# IP-Adapter-FaceID\n",
        "print(\"Downloading IP-Adapter-FaceID...\")\n",
        "snapshot_download(repo_id=\"h94/IP-Adapter-FaceID\", local_dir=f\"{base_dir}/hf_downloads/IP-Adapter-FaceID\", allow_patterns=[\"*.safetensors\", \"*.bin\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/IP-Adapter-FaceID\", base_dir)\n",
        "\n",
        "# NSFWmodel\n",
        "print(\"Downloading NSFWmodel...\")\n",
        "snapshot_download(repo_id=\"lexa862/NSFWmodel\", local_dir=f\"{base_dir}/hf_downloads/NSFWmodel\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/NSFWmodel\", base_dir)\n",
        "\n",
        "# illuminatiDiffusionV1_v11_unCLIP\n",
        "print(\"Downloading illuminatiDiffusionV1_v11_unCLIP...\")\n",
        "snapshot_download(repo_id=\"comfyanonymous/illuminatiDiffusionV1_v11_unCLIP\", local_dir=f\"{base_dir}/hf_downloads/illuminatiDiffusionV1_v11_unCLIP\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/illuminatiDiffusionV1_v11_unCLIP\", base_dir)\n",
        "\n",
        "# wd-1.5-beta2_unCLIP\n",
        "print(\"Downloading wd-1.5-beta2_unCLIP...\")\n",
        "snapshot_download(repo_id=\"comfyanonymous/wd-1.5-beta2_unCLIP\", local_dir=f\"{base_dir}/hf_downloads/wd-1.5-beta2_unCLIP\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/wd-1.5-beta2_unCLIP\", base_dir)\n",
        "\n",
        "# sd-vae-ft-mse-original\n",
        "print(\"Downloading sd-vae-ft-mse-original...\")\n",
        "snapshot_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", local_dir=f\"{base_dir}/hf_downloads/sd-vae-ft-mse-original\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/sd-vae-ft-mse-original\", base_dir)\n",
        "\n",
        "# Waifu Diffusion v1.4\n",
        "print(\"Downloading Waifu Diffusion v1.4...\")\n",
        "snapshot_download(repo_id=\"hakurei/waifu-diffusion-v1-4\", local_dir=f\"{base_dir}/hf_downloads/Waifu_Diffusion_v1.4\", allow_patterns=[\"*.safetensors\", \"*.ckpt\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/Waifu_Diffusion_v1.4\", base_dir)\n",
        "\n",
        "# clip-vit-large-patch14\n",
        "print(\"Downloading clip-vit-large-patch14...\")\n",
        "snapshot_download(repo_id=\"openai/clip-vit-large-patch14\", local_dir=f\"{base_dir}/hf_downloads/clip-vit-large-patch14\", allow_patterns=[\"*.bin\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/clip-vit-large-patch14\", base_dir)\n",
        "\n",
        "# ControlNet-v1-1_fp16_safetensors (example, adjust as needed)\n",
        "print(\"Downloading ControlNet-v1-1_fp16_safetensors...\")\n",
        "snapshot_download(repo_id=\"comfyanonymous/ControlNet-v1-1_fp16_safetensors\", local_dir=f\"{base_dir}/hf_downloads/ControlNet-v1-1_fp16_safetensors\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/ControlNet-v1-1_fp16_safetensors\", base_dir)\n",
        "\n",
        "# Control-LoRA Model\n",
        "print(\"Downloading Control-LoRA Model...\")\n",
        "snapshot_download(repo_id=\"stabilityai/control-lora\", local_dir=f\"{base_dir}/hf_downloads/Control-LoRA_Model\", allow_patterns=[\"*.safetensors\"], ignore_patterns=[\"*.git*\"])\n",
        "sort_hf_files(f\"{base_dir}/hf_downloads/Control-LoRA_Model\", base_dir)\n",
        "\n",
        "# GLIGEN\n",
        "!echo -= Downloading GLIGEN =-\n",
        "!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -O {base_dir}/gligen/gligen_sd14_textbox_pruned_fp16.safetensors\n",
        "\n",
        "# ESRGAN upscale models\n",
        "!echo -= Downloading ESRGAN upscale models =-\n",
        "!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -O {base_dir}/upscale_models/RealESRGAN_x4plus.pth\n",
        "!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -O {base_dir}/upscale_models/RealESRGAN_x2.pth\n",
        "!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -O {base_dir}/upscale_models/RealESRGAN_x4.pth\n",
        "\n",
        "# Verify downloads\n",
        "!echo -= Verifying Downloads =-\n",
        "!ls -lh {base_dir}/checkpoints/\n",
        "!ls -lh {base_dir}/loras/\n",
        "!ls -lh {base_dir}/ipadapter/\n",
        "!ls -lh {base_dir}/vae/\n",
        "!ls -lh {base_dir}/clip_vision/\n",
        "!ls -lh {base_dir}/controlnet/\n",
        "!ls -lh {base_dir}/style_models/\n",
        "!ls -lh {base_dir}/gligen/\n",
        "!ls -lh {base_dir}/upscale_models/\n",
        "\n",
        "!echo -= Done =-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gxv1ehd7VUU4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}